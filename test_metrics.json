{
  "metrics": {
    "coverage_rate": 100.0,
    "success_rate": 61.111111111111114,
    "partial_success_rate": 0.0
  },
  "status": "success",
  "model_name": "accounts/fireworks/models/llama-v3p3-70b-instruct",
  "timestamp": "2025-01-19T00:22:54.600442",
  "results": [
    {
      "test_name": "tests/test_code_generation.py::test_function_implementation",
      "outcome": "passed",
      "error_message": null,
      "duration": 5.184632222000005,
      "timestamp": "2025-01-19T00:22:24.424163"
    },
    {
      "test_name": "tests/test_code_generation.py::test_algorithm_solutions",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0dcda40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\n\n    @pytest.mark.asyncio\n    async def test_algorithm_solutions(llm_client, db_session):\n        \"\"\"Test implementation of common algorithms.\"\"\"\n        client = await llm_client\n    \n        algorithms = [\n            {\n                \"name\": \"Binary Search\",\n                \"prompt\": \"\"\"\n                Implement a binary search function in Python that finds the index of a\n                target value in a sorted list. Return -1 if the target is not found.\n                Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Input validation\",\n                    \"Handle empty list\",\n                    \"Return correct index\",\n                    \"Return -1 if not found\"\n                ]\n            },\n            {\n                \"name\": \"Merge Sort\",\n                \"prompt\": \"\"\"\n                Implement the merge sort algorithm in Python to sort a list of numbers\n                in ascending order. Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Divide and conquer approach\",\n                    \"Merge function\",\n                    \"Handle empty or single-element lists\",\n                    \"Maintain stable sort\"\n                ]\n            }\n        ]\n    \n        for algo in algorithms:\n            response = await client.generate(\n                prompt=algo[\"prompt\"],\n                max_tokens=500,\n                temperature=0.0\n            )\n    \n            raw_code = response[\"choices\"][0][\"text\"].strip()\n            code = extract_code_block(raw_code)\n    \n            # Verify syntax\n            try:\n                ast.parse(code)\n            except SyntaxError as e:\n                pytest.fail(f\"Generated {algo['name']} code has syntax error: {e}\\nCode:\\n{code}\")\n    \n            # Check for algorithm-specific requirements\n            for req in algo[\"requirements\"]:\n>               assert any(keyword in code.lower() for keyword in req.lower().split()), \\\n                    f\"Missing requirement: {req}\"\nE               AssertionError: Missing requirement: Input validation\nE               assert False\nE                +  where False = any(<generator object test_algorithm_solutions.<locals>.<genexpr> at 0x7f81e0dc7660>)\n\ntests/test_code_generation.py:138: AssertionError",
      "duration": 3.7756513809999888,
      "timestamp": "2025-01-19T00:22:28.252036"
    },
    {
      "test_name": "tests/test_code_generation.py::test_code_refactoring",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e09c4ac0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\n\n    @pytest.mark.asyncio\n    async def test_code_refactoring(llm_client, db_session):\n        \"\"\"Test code refactoring capabilities.\"\"\"\n        client = await llm_client\n    \n        original_code = \"\"\"\n        def process_data(data):\n            result = []\n            for i in range(len(data)):\n                if data[i] > 0:\n                    if data[i] % 2 == 0:\n                        if data[i] < 100:\n                            result.append(data[i] * 2)\n            return result\n        \"\"\"\n    \n        refactor_prompt = f\"\"\"\n        Refactor this code to improve readability and efficiency. The code should:\n        1. Use list comprehension\n        2. Reduce nesting\n        3. Add type hints\n        4. Add docstring\n    \n        Return the refactored code in a Python code block.\n    \n        Original code:\n        {original_code}\n        \"\"\"\n    \n        response = await client.generate(\n            prompt=refactor_prompt,\n            max_tokens=400,\n            temperature=0.0\n        )\n    \n        raw_code = response[\"choices\"][0][\"text\"].strip()\n        refactored_code = extract_code_block(raw_code)\n    \n        # Verify syntax first\n        try:\n            ast.parse(refactored_code)\n        except SyntaxError as e:\n            pytest.fail(f\"Generated code has syntax error: {e}\\nCode:\\n{refactored_code}\")\n    \n        # Check for improvements\n        required_elements = [\n            \"def process_data\",\n            \"List[\",  # Type hints\n            '\"\"\"',    # Docstring\n            \"[\",      # List comprehension\n            \"return\"\n        ]\n    \n        for element in required_elements:\n>           assert element in refactored_code, f\"Missing element in refactored code: {element}\"\nE           AssertionError: Missing element in refactored code: List[\nE           assert 'List[' in 'def process_data(data: list[int]) -> list[int]:\\n    \"\"\"\\n    This function processes a list of integers, filtering out non-positive numbers, \\n    odd numbers, and numbers greater than or equal to 100. It then doubles the \\n    remaining numbers and returns them in a new list.\\n\\n    Args:\\n        data (list[int]): A list of integers to be processed.\\n\\n    Returns:\\n        list[int]: A list of doubled integers that meet the specified conditions.\\n    \"\"\"\\n    # Use list comprehension to filter and transform the data in a single step\\n    result = [num * 2 for num in data if num > 0 and num % 2 == 0 and num < 100]\\n    return result\\n\\n# Example usage:\\nif __name__ == \"__main__\":\\n    data = [10, 20, 30, 40, 50, 101, -10, 0]\\n    print(process_data(data))'\n\ntests/test_code_generation.py:195: AssertionError",
      "duration": 3.0597771369999975,
      "timestamp": "2025-01-19T00:22:31.321489"
    },
    {
      "test_name": "tests/test_code_generation.py::test_error_handling",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0dcdac0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\n\n    @pytest.mark.asyncio\n    async def test_error_handling(llm_client, db_session):\n        \"\"\"Test generation of code with proper error handling.\"\"\"\n        client = await llm_client\n    \n        prompt = \"\"\"\n        Write a Python function that reads a JSON file and extracts specific fields.\n        The function should handle all possible errors (file not found, invalid JSON,\n        missing fields) gracefully. Return the code in a Python code block.\n        \"\"\"\n    \n        response = await client.generate(\n            prompt=prompt,\n            max_tokens=400,\n            temperature=0.0\n        )\n    \n        raw_code = response[\"choices\"][0][\"text\"].strip()\n        code = extract_code_block(raw_code)\n    \n        # Verify syntax first\n        try:\n            ast.parse(code)\n        except SyntaxError as e:\n            pytest.fail(f\"Generated code has syntax error: {e}\\nCode:\\n{code}\")\n    \n        # Check for error handling constructs\n        required_elements = [\n            \"try:\",\n            \"except\",\n            \"FileNotFoundError\",\n            \"json.JSONDecodeError\",\n            \"raise\"\n        ]\n    \n        for element in required_elements:\n>           assert element in code, f\"Missing error handling element: {element}\"\nE           AssertionError: Missing error handling element: raise\nE           assert 'raise' in 'import json\\n\\ndef extract_fields_from_json(file_path, fields):\\n    \"\"\"\\n    Reads a JSON file and extracts specific fields.\\n\\n    Args:\\n        file_path (str): The path to the JSON file.\\n        fields (list): A list of fields to extract.\\n\\n    Returns:\\n        dict: A dictionary containing the extracted fields. If a field is missing, it will be None.\\n    \"\"\"\\n\\n    try:\\n        # Attempt to open the file\\n        with open(file_path, \\'r\\') as file:\\n            # Attempt to parse the JSON\\n            data = json.load(file)\\n    except FileNotFoundError:\\n        print(f\"Error: The file \\'{file_path}\\' was not found.\")\\n        return {}\\n    except json.JSONDecodeError as e:\\n        print(f\"Error: Invalid JSON in file \\'{file_path}\\': {e}\")\\n        return {}\\n\\n    # Initialize a dictionary to store the extracted fields\\n    extracted_fields = {}\\n\\n    # Iterate over each field\\n    for field in fields:\\n        # Attempt to extract the field\\n        try:\\n            extracted_fields[field] = data[field]\\n        except KeyError:\\n            # If the field is missing, set it to None\\n            extracted_fields[field] = None\\n\\n    return extracted_fields\\n\\n\\n# Example usage:\\nif __name__ == \"__main__\":\\n    file_path = \"example.json\"\\n    fields = [\"name\", \"age\", \"city\"]\\n\\n    extracted_fields = extract_fields_from_json(file_path, fields)\\n\\n    print(\"Extracted Fields:\")\\n    for field, value in extracted_fields.items():\\n        print(f\"{field}: {value}\")'\n\ntests/test_code_generation.py:238: AssertionError",
      "duration": 4.608472983000013,
      "timestamp": "2025-01-19T00:22:35.938564"
    },
    {
      "test_name": "tests/test_few_shot.py::test_sentiment_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 4.10234201099999,
      "timestamp": "2025-01-19T00:22:40.043075"
    },
    {
      "test_name": "tests/test_few_shot.py::test_topic_classification",
      "outcome": "passed",
      "error_message": null,
      "duration": 2.9593655820000038,
      "timestamp": "2025-01-19T00:22:43.004578"
    },
    {
      "test_name": "tests/test_few_shot.py::test_intent_classification",
      "outcome": "passed",
      "error_message": null,
      "duration": 4.042337696000004,
      "timestamp": "2025-01-19T00:22:47.049024"
    },
    {
      "test_name": "tests/test_few_shot.py::test_entity_extraction",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0beeac0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\n\n    @pytest.mark.asyncio\n    async def test_entity_extraction(llm_client, db_session):\n        \"\"\"Test named entity extraction with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"John Smith works at Apple Inc. in California\",\n                \"entities\": {\n                    \"person\": \"John Smith\",\n                    \"organization\": \"Apple Inc.\",\n                    \"location\": \"California\"\n                }\n            },\n            {\n                \"text\": \"Microsoft CEO Satya Nadella visited London\",\n                \"entities\": {\n                    \"person\": \"Satya Nadella\",\n                    \"organization\": \"Microsoft\",\n                    \"location\": \"London\"\n                }\n            }\n        ]\n    \n        test_cases = [\n            {\n                \"text\": \"Amazon founder Jeff Bezos spoke in Seattle\",\n                \"expected\": {\n                    \"person\": \"Jeff Bezos\",\n                    \"organization\": \"Amazon\",\n                    \"location\": \"Seattle\"\n                }\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Extract the person, organization, and location from the text:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\n\"\n            few_shot_prompt += f\"Entities: {json.dumps(example['entities'], indent=2)}\\n\\n\"\n    \n        for case in test_cases:\n            prompt = few_shot_prompt + f\"Text: {case['text']}\\nEntities:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.3\n            )\n    \n            # Extract JSON from response\n            try:\n>               prediction = json.loads(response[\"choices\"][0][\"text\"].strip())\n\ntests/test_few_shot.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/__init__.py:346: in loads\n    return _default_decoder.decode(s)\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <json.decoder.JSONDecoder object at 0x7f81e35c1880>\ns = 'Based on the pattern, I\\'ll extract the entities from the text:\\n\\nEntities: {\\n  \"person\": \"Jeff Bezos\",\\n  \"organization\": \"Amazon\",\\n  \"location\": \"Seattle\"\\n}'\nidx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/decoder.py:355: JSONDecodeError\n\nDuring handling of the above exception, another exception occurred:\n\nllm_client = <coroutine object llm_client at 0x7f81e0beeac0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\n\n    @pytest.mark.asyncio\n    async def test_entity_extraction(llm_client, db_session):\n        \"\"\"Test named entity extraction with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"John Smith works at Apple Inc. in California\",\n                \"entities\": {\n                    \"person\": \"John Smith\",\n                    \"organization\": \"Apple Inc.\",\n                    \"location\": \"California\"\n                }\n            },\n            {\n                \"text\": \"Microsoft CEO Satya Nadella visited London\",\n                \"entities\": {\n                    \"person\": \"Satya Nadella\",\n                    \"organization\": \"Microsoft\",\n                    \"location\": \"London\"\n                }\n            }\n        ]\n    \n        test_cases = [\n            {\n                \"text\": \"Amazon founder Jeff Bezos spoke in Seattle\",\n                \"expected\": {\n                    \"person\": \"Jeff Bezos\",\n                    \"organization\": \"Amazon\",\n                    \"location\": \"Seattle\"\n                }\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Extract the person, organization, and location from the text:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\n\"\n            few_shot_prompt += f\"Entities: {json.dumps(example['entities'], indent=2)}\\n\\n\"\n    \n        for case in test_cases:\n            prompt = few_shot_prompt + f\"Text: {case['text']}\\nEntities:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.3\n            )\n    \n            # Extract JSON from response\n            try:\n                prediction = json.loads(response[\"choices\"][0][\"text\"].strip())\n                for entity_type, expected_value in case[\"expected\"].items():\n                    assert expected_value.lower() in prediction[entity_type].lower(), \\\n                        f\"Expected {expected_value} in {entity_type}\"\n            except json.JSONDecodeError:\n>               pytest.fail(\"Response is not valid JSON\")\nE               Failed: Response is not valid JSON\n\ntests/test_few_shot.py:216: Failed",
      "duration": 0.9274093939999943,
      "timestamp": "2025-01-19T00:22:48.046189"
    },
    {
      "test_name": "tests/test_mathematics.py::test_arithmetic_operations",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0bdb7c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7f81e0c19ca0>\n\n    @pytest.mark.asyncio\n    async def test_arithmetic_operations(llm_client, db_session, make_test_suite):\n        \"\"\"Test basic arithmetic operations.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"arithmetic\",\n            description=\"Tests for basic arithmetic operations\",\n            category=\"mathematics\"\n        )\n    \n        test_cases = [\n            {\n                \"prompt\": \"What is the result of multiplying 23.5 by 8.75?\",\n                \"expected\": 205.625\n            },\n            {\n                \"prompt\": \"What is 1234 divided by 56.5?\",\n                \"expected\": 21.84070796460177\n            }\n        ]\n    \n        for i, case in enumerate(test_cases):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Arithmetic Test {i+1}\",\n                test_type=\"arithmetic\",\n                input_data={\"prompt\": case[\"prompt\"]},\n                expected_output={\"result\": case[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for case in test_cases:\n            response = await client.generate(\n                prompt=f\"{case['prompt']} Provide only the numerical answer without any explanation.\",\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\n>           assert abs(result - case[\"expected\"]) < 0.01, \\\n                f\"Expected {case['expected']} but got {result}\"\nE           AssertionError: Expected 21.84070796460177 but got 21.86\nE           assert 0.019292035398230212 < 0.01\nE            +  where 0.019292035398230212 = abs((21.86 - 21.84070796460177))\n\ntests/test_mathematics.py:52: AssertionError",
      "duration": 0.9424907749999818,
      "timestamp": "2025-01-19T00:22:48.999504"
    },
    {
      "test_name": "tests/test_mathematics.py::test_word_problems",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.642941884999999,
      "timestamp": "2025-01-19T00:22:49.654834"
    },
    {
      "test_name": "tests/test_mathematics.py::test_basic_algebra",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.6117057299999829,
      "timestamp": "2025-01-19T00:22:50.275002"
    },
    {
      "test_name": "tests/test_mathematics.py::test_mathematical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.45158287900000005,
      "timestamp": "2025-01-19T00:22:50.734432"
    },
    {
      "test_name": "tests/test_reasoning.py::test_logical_deduction",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0bdb6c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7f81e0ad5940>\n\n    @pytest.mark.asyncio\n    async def test_logical_deduction(llm_client, db_session, make_test_suite):\n        \"\"\"Test logical deduction capabilities.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"logical_deduction\",\n            description=\"Tests for logical deduction\",\n            category=\"reasoning\"\n        )\n    \n        premises = \"\"\"\n        1. All programmers like coffee\n        2. Some coffee drinkers work at night\n        3. Alice is a programmer\n        \"\"\"\n    \n        questions = [\n            {\n                \"query\": \"Does Alice like coffee?\",\n                \"expected_keywords\": [\"yes\", \"true\", \"likes\", \"does\"]\n            },\n            {\n                \"query\": \"Do all programmers work at night?\",\n                \"expected_keywords\": [\"cannot\", \"unknown\", \"insufficient\", \"maybe\"]\n            }\n        ]\n    \n        for i, question in enumerate(questions):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Deduction Test {i+1}\",\n                test_type=\"logical_deduction\",\n                input_data={\n                    \"premises\": premises,\n                    \"question\": question[\"query\"]\n                },\n                expected_output={\"keywords\": question[\"expected_keywords\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for question in questions:\n            prompt = f\"\"\"\n            Given these premises:\n            {premises}\n    \n            Question: {question[\"query\"]}\n            Provide a direct answer without explanation.\n            \"\"\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            answer = response[\"choices\"][0][\"text\"].strip().lower()\n>           assert any(keyword in answer for keyword in question[\"expected_keywords\"]), \\\n                f\"Answer '{answer}' does not contain any expected keywords: {question['expected_keywords']}\"\nE           AssertionError: Answer 'no.' does not contain any expected keywords: ['cannot', 'unknown', 'insufficient', 'maybe']\nE           assert False\nE            +  where False = any(<generator object test_logical_deduction.<locals>.<genexpr> at 0x7f81e0bda2e0>)\n\ntests/test_reasoning.py:68: AssertionError",
      "duration": 1.1246554079999953,
      "timestamp": "2025-01-19T00:22:51.877937"
    },
    {
      "test_name": "tests/test_reasoning.py::test_cause_effect_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.5904806389999919,
      "timestamp": "2025-01-19T00:22:52.476536"
    },
    {
      "test_name": "tests/test_reasoning.py::test_analogical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.6563032239999984,
      "timestamp": "2025-01-19T00:22:53.140447"
    },
    {
      "test_name": "tests/test_summarization.py::test_article_summarization",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7f81e0beeb40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7f81e0e65d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7f81e0b8c310>\n\n    @pytest.mark.asyncio\n    async def test_article_summarization(llm_client, db_session, make_test_suite):\n        \"\"\"Test article summarization capabilities.\"\"\"\n        # Need to await our async fixture\n        client = await llm_client\n    \n        # Create a uniquely named test suite\n        suite = make_test_suite(\n            name_prefix=\"summarization\",\n            description=\"Tests for text summarization capabilities\",\n            category=\"summarization\"\n        )\n    \n        # Test article\n        article = \"\"\"\n        The James Webb Space Telescope has revolutionized our view of the cosmos.\n        Launched in December 2021, this $10 billion observatory has provided\n        unprecedented views of distant galaxies, star-forming regions, and\n        exoplanets. Its infrared capabilities allow it to peer through cosmic\n        dust and see light from the earliest galaxies in the universe.\n        \"\"\"\n    \n        # Define expected key points\n        key_points = [\n            \"James Webb Space Telescope\",\n            \"launched December 2021\",\n            \"infrared observation\",\n            \"galaxies and exoplanets\"\n        ]\n    \n        # Create test case in database\n        test_case = UnitTest(\n            test_id=uuid.uuid4(),\n            suite_id=suite.suite_id,\n            test_name=\"Article Summarization\",\n            test_type=\"summarization\",\n            test_description=\"Test summarization of a scientific article\",\n            input_data={\"article\": article},\n            expected_output={\"key_points\": key_points}\n        )\n        db_session.add(test_case)\n        db_session.commit()\n    \n        # Get summary from model\n        response = await client.generate(\n            prompt=f\"Please summarize this article concisely: {article}\",\n            max_tokens=100,\n            temperature=0.3\n        )\n    \n        summary = response[\"choices\"][0][\"text\"].strip()\n    \n        # Check if key points are present\n        for point in key_points:\n>           assert point.lower() in summary.lower(), f\"Missing key point: {point}\"\nE           AssertionError: Missing key point: launched December 2021\nE           assert 'launched december 2021' in 'the james webb space telescope, launched in 2021, has transformed our understanding of the universe with its infrared capabilities, providing unprecedented views of distant galaxies, star-forming regions, and exoplanets.'\nE            +  where 'launched december 2021' = <built-in method lower of str object at 0x7f81e0e6d120>()\nE            +    where <built-in method lower of str object at 0x7f81e0e6d120> = 'launched December 2021'.lower\nE            +  and   'the james webb space telescope, launched in 2021, has transformed our understanding of the universe with its infrared capabilities, providing unprecedented views of distant galaxies, star-forming regions, and exoplanets.' = <built-in method lower of str object at 0x7f81e0e56cf0>()\nE            +    where <built-in method lower of str object at 0x7f81e0e56cf0> = 'The James Webb Space Telescope, launched in 2021, has transformed our understanding of the universe with its infrared capabilities, providing unprecedented views of distant galaxies, star-forming regions, and exoplanets.'.lower\n\ntests/test_summarization.py:64: AssertionError",
      "duration": 1.4308264240000028,
      "timestamp": "2025-01-19T00:22:54.588002"
    },
    {
      "test_name": "tests/test_summarization.py::test_multi_document_summarization",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.0002747369999838156,
      "timestamp": "2025-01-19T00:22:54.597033"
    },
    {
      "test_name": "tests/test_summarization.py::test_bullet_point_extraction",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.0002157559999886871,
      "timestamp": "2025-01-19T00:22:54.598573"
    }
  ]
}