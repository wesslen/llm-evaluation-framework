{
  "metrics": {
    "coverage_rate": 100.0,
    "success_rate": 44.44444444444444,
    "partial_success_rate": 0.0
  },
  "status": "success",
  "model_name": "/models/NousResearch/Meta-Llama-3.1-8B-Instruct",
  "timestamp": "2025-01-19T00:02:29.637060",
  "results": [
    {
      "test_name": "tests/test_code_generation.py::test_function_implementation",
      "outcome": "passed",
      "error_message": null,
      "duration": 38.15591320500002,
      "timestamp": "2025-01-19T00:01:30.823877"
    },
    {
      "test_name": "tests/test_code_generation.py::test_algorithm_solutions",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec68b9c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_algorithm_solutions(llm_client, db_session):\n        \"\"\"Test implementation of common algorithms.\"\"\"\n        client = await llm_client\n    \n        algorithms = [\n            {\n                \"name\": \"Binary Search\",\n                \"prompt\": \"\"\"\n                Implement a binary search function in Python that finds the index of a\n                target value in a sorted list. Return -1 if the target is not found.\n                Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Input validation\",\n                    \"Handle empty list\",\n                    \"Return correct index\",\n                    \"Return -1 if not found\"\n                ]\n            },\n            {\n                \"name\": \"Merge Sort\",\n                \"prompt\": \"\"\"\n                Implement the merge sort algorithm in Python to sort a list of numbers\n                in ascending order. Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Divide and conquer approach\",\n                    \"Merge function\",\n                    \"Handle empty or single-element lists\",\n                    \"Maintain stable sort\"\n                ]\n            }\n        ]\n    \n        for algo in algorithms:\n            response = await client.generate(\n                prompt=algo[\"prompt\"],\n                max_tokens=500,\n                temperature=0.0\n            )\n    \n            raw_code = response[\"choices\"][0][\"text\"].strip()\n            code = extract_code_block(raw_code)\n    \n            # Verify syntax\n            try:\n                ast.parse(code)\n            except SyntaxError as e:\n                pytest.fail(f\"Generated {algo['name']} code has syntax error: {e}\\nCode:\\n{code}\")\n    \n            # Check for algorithm-specific requirements\n            for req in algo[\"requirements\"]:\n>               assert any(keyword in code.lower() for keyword in req.lower().split()), \\\n                    f\"Missing requirement: {req}\"\nE               AssertionError: Missing requirement: Input validation\nE               assert False\nE                +  where False = any(<generator object test_algorithm_solutions.<locals>.<genexpr> at 0x7fbbec687580>)\n\ntests/test_code_generation.py:138: AssertionError",
      "duration": 13.464036864000008,
      "timestamp": "2025-01-19T00:01:44.333046"
    },
    {
      "test_name": "tests/test_code_generation.py::test_code_refactoring",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec68b5c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_code_refactoring(llm_client, db_session):\n        \"\"\"Test code refactoring capabilities.\"\"\"\n        client = await llm_client\n    \n        original_code = \"\"\"\n        def process_data(data):\n            result = []\n            for i in range(len(data)):\n                if data[i] > 0:\n                    if data[i] % 2 == 0:\n                        if data[i] < 100:\n                            result.append(data[i] * 2)\n            return result\n        \"\"\"\n    \n        refactor_prompt = f\"\"\"\n        Refactor this code to improve readability and efficiency. The code should:\n        1. Use list comprehension\n        2. Reduce nesting\n        3. Add type hints\n        4. Add docstring\n    \n        Return the refactored code in a Python code block.\n    \n        Original code:\n        {original_code}\n        \"\"\"\n    \n        response = await client.generate(\n            prompt=refactor_prompt,\n            max_tokens=400,\n            temperature=0.0\n        )\n    \n        raw_code = response[\"choices\"][0][\"text\"].strip()\n        refactored_code = extract_code_block(raw_code)\n    \n        # Verify syntax first\n        try:\n            ast.parse(refactored_code)\n        except SyntaxError as e:\n            pytest.fail(f\"Generated code has syntax error: {e}\\nCode:\\n{refactored_code}\")\n    \n        # Check for improvements\n        required_elements = [\n            \"def process_data\",\n            \"List[\",  # Type hints\n            '\"\"\"',    # Docstring\n            \"[\",      # List comprehension\n            \"return\"\n        ]\n    \n        for element in required_elements:\n>           assert element in refactored_code, f\"Missing element in refactored code: {element}\"\nE           AssertionError: Missing element in refactored code: List[\nE           assert 'List[' in 'def process_data(data: list[int]) -> list[int]:\\n    \"\"\"\\n    Process a list of integers by multiplying even numbers less than 100 by 2.\\n\\n    Args:\\n        data (list[int]): A list of integers.\\n\\n    Returns:\\n        list[int]: A list of processed integers.\\n    \"\"\"\\n    return [x * 2 for x in data if x > 0 and x % 2 == 0 and x < 100]'\n\ntests/test_code_generation.py:195: AssertionError",
      "duration": 10.126452639000007,
      "timestamp": "2025-01-19T00:01:54.465784"
    },
    {
      "test_name": "tests/test_code_generation.py::test_error_handling",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec4057c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_error_handling(llm_client, db_session):\n        \"\"\"Test generation of code with proper error handling.\"\"\"\n        client = await llm_client\n    \n        prompt = \"\"\"\n        Write a Python function that reads a JSON file and extracts specific fields.\n        The function should handle all possible errors (file not found, invalid JSON,\n        missing fields) gracefully. Return the code in a Python code block.\n        \"\"\"\n    \n        response = await client.generate(\n            prompt=prompt,\n            max_tokens=400,\n            temperature=0.0\n        )\n    \n        raw_code = response[\"choices\"][0][\"text\"].strip()\n        code = extract_code_block(raw_code)\n    \n        # Verify syntax first\n        try:\n            ast.parse(code)\n        except SyntaxError as e:\n            pytest.fail(f\"Generated code has syntax error: {e}\\nCode:\\n{code}\")\n    \n        # Check for error handling constructs\n        required_elements = [\n            \"try:\",\n            \"except\",\n            \"FileNotFoundError\",\n            \"json.JSONDecodeError\",\n            \"raise\"\n        ]\n    \n        for element in required_elements:\n>           assert element in code, f\"Missing error handling element: {element}\"\nE           AssertionError: Missing error handling element: raise\nE           assert 'raise' in 'import json\\n\\ndef extract_fields_from_json(file_path, fields):\\n    \"\"\"\\n    Extract specific fields from a JSON file.\\n\\n    Args:\\n        file_path (str): Path to the JSON file.\\n        fields (list): List of field names to extract.\\n\\n    Returns:\\n        dict: Dictionary with extracted fields.\\n\\n    Raises:\\n        FileNotFoundError: If the file does not exist.\\n        json.JSONDecodeError: If the file contains invalid JSON.\\n        KeyError: If a field is missing from the JSON data.\\n    \"\"\"\\n    try:\\n        with open(file_path, \\'r\\') as file:\\n            data = json.load(file)\\n    except FileNotFoundError:\\n        print(f\"Error: File \\'{file_path}\\' not found.\")\\n        return None\\n    except json.JSONDecodeError as e:\\n        print(f\"Error: Invalid JSON in file \\'{file_path}\\': {e}\")\\n        return None\\n\\n    extracted_data = {}\\n    for field in fields:\\n        try:\\n            extracted_data[field] = data[field]\\n        except KeyError:\\n            print(f\"Warning: Field \\'{field}\\' is missing from the JSON data.\")\\n\\n    return extracted_data'\n\ntests/test_code_generation.py:238: AssertionError",
      "duration": 15.179013932000004,
      "timestamp": "2025-01-19T00:02:09.650816"
    },
    {
      "test_name": "tests/test_few_shot.py::test_sentiment_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 4.189223814000002,
      "timestamp": "2025-01-19T00:02:13.841738"
    },
    {
      "test_name": "tests/test_few_shot.py::test_topic_classification",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec405440>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_topic_classification(llm_client, db_session):\n        \"\"\"Test topic classification with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"Scientists discover new exoplanet in nearby solar system\",\n                \"topic\": \"science\"\n            },\n            {\n                \"text\": \"Local team wins championship in dramatic final\",\n                \"topic\": \"sports\"\n            },\n            {\n                \"text\": \"New smartphone features revolutionary camera technology\",\n                \"topic\": \"technology\"\n            }\n        ]\n    \n        test_articles = [\n            {\n                \"text\": \"Researchers develop breakthrough in quantum computing\",\n                \"expected\": \"technology\"\n            },\n            {\n                \"text\": \"Study reveals new insights into black hole formation\",\n                \"expected\": \"science\"\n            },\n            {\n                \"text\": \"Player breaks record for most goals in a season\",\n                \"expected\": \"sports\"\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Classify the topic of the following text as science, sports, or technology:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\nTopic: {example['topic']}\\n\\n\"\n    \n        for article in test_articles:\n            prompt = few_shot_prompt + f\"Text: {article['text']}\\nTopic:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=50,\n                temperature=0.3\n            )\n    \n            prediction = response[\"choices\"][0][\"text\"].strip().lower()\n>           assert article[\"expected\"] in prediction, \\\n                f\"Expected {article['expected']} but got {prediction}\"\nE           AssertionError: Expected technology but got based on the text, i would classify the topic as:\nE             \nE             **science**\nE             \nE             this is because the text mentions \"researchers\" and \"breakthrough\" in the context of \"quantum computing\", which is a scientific field of study.\nE           assert 'technology' in 'based on the text, i would classify the topic as:\\n\\n**science**\\n\\nthis is because the text mentions \"researchers\" and \"breakthrough\" in the context of \"quantum computing\", which is a scientific field of study.'\n\ntests/test_few_shot.py:103: AssertionError",
      "duration": 1.903050310999987,
      "timestamp": "2025-01-19T00:02:15.751315"
    },
    {
      "test_name": "tests/test_few_shot.py::test_intent_classification",
      "outcome": "passed",
      "error_message": null,
      "duration": 4.622650252,
      "timestamp": "2025-01-19T00:02:20.375546"
    },
    {
      "test_name": "tests/test_few_shot.py::test_entity_extraction",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec432740>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_entity_extraction(llm_client, db_session):\n        \"\"\"Test named entity extraction with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"John Smith works at Apple Inc. in California\",\n                \"entities\": {\n                    \"person\": \"John Smith\",\n                    \"organization\": \"Apple Inc.\",\n                    \"location\": \"California\"\n                }\n            },\n            {\n                \"text\": \"Microsoft CEO Satya Nadella visited London\",\n                \"entities\": {\n                    \"person\": \"Satya Nadella\",\n                    \"organization\": \"Microsoft\",\n                    \"location\": \"London\"\n                }\n            }\n        ]\n    \n        test_cases = [\n            {\n                \"text\": \"Amazon founder Jeff Bezos spoke in Seattle\",\n                \"expected\": {\n                    \"person\": \"Jeff Bezos\",\n                    \"organization\": \"Amazon\",\n                    \"location\": \"Seattle\"\n                }\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Extract the person, organization, and location from the text:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\n\"\n            few_shot_prompt += f\"Entities: {json.dumps(example['entities'], indent=2)}\\n\\n\"\n    \n        for case in test_cases:\n            prompt = few_shot_prompt + f\"Text: {case['text']}\\nEntities:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.3\n            )\n    \n            # Extract JSON from response\n            try:\n>               prediction = json.loads(response[\"choices\"][0][\"text\"].strip())\n\ntests/test_few_shot.py:211: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/__init__.py:346: in loads\n    return _default_decoder.decode(s)\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/decoder.py:337: in decode\n    obj, end = self.raw_decode(s, idx=_w(s, 0).end())\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = <json.decoder.JSONDecoder object at 0x7fbbeee97880>\ns = 'Here are the extracted entities:\\n\\n**Text 1:**\\nEntities: {\\n  \"person\": \"John Smith\",\\n  \"organization\": \"Apple Inc...on\"\\n}\\n\\n**Text 3:**\\nEntities: {\\n  \"person\": \"Jeff Bezos\",\\n  \"organization\": \"Amazon\",\\n  \"location\": \"Seattle\"\\n}'\nidx = 0\n\n    def raw_decode(self, s, idx=0):\n        \"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\n        a JSON document) and return a 2-tuple of the Python\n        representation and the index in ``s`` where the document ended.\n    \n        This can be used to decode a JSON document from a string that may\n        have extraneous data at the end.\n    \n        \"\"\"\n        try:\n            obj, end = self.scan_once(s, idx)\n        except StopIteration as err:\n>           raise JSONDecodeError(\"Expecting value\", s, err.value) from None\nE           json.decoder.JSONDecodeError: Expecting value: line 1 column 1 (char 0)\n\n/opt/hostedtoolcache/Python/3.9.21/x64/lib/python3.9/json/decoder.py:355: JSONDecodeError\n\nDuring handling of the above exception, another exception occurred:\n\nllm_client = <coroutine object llm_client at 0x7fbbec432740>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\n\n    @pytest.mark.asyncio\n    async def test_entity_extraction(llm_client, db_session):\n        \"\"\"Test named entity extraction with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"John Smith works at Apple Inc. in California\",\n                \"entities\": {\n                    \"person\": \"John Smith\",\n                    \"organization\": \"Apple Inc.\",\n                    \"location\": \"California\"\n                }\n            },\n            {\n                \"text\": \"Microsoft CEO Satya Nadella visited London\",\n                \"entities\": {\n                    \"person\": \"Satya Nadella\",\n                    \"organization\": \"Microsoft\",\n                    \"location\": \"London\"\n                }\n            }\n        ]\n    \n        test_cases = [\n            {\n                \"text\": \"Amazon founder Jeff Bezos spoke in Seattle\",\n                \"expected\": {\n                    \"person\": \"Jeff Bezos\",\n                    \"organization\": \"Amazon\",\n                    \"location\": \"Seattle\"\n                }\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Extract the person, organization, and location from the text:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\n\"\n            few_shot_prompt += f\"Entities: {json.dumps(example['entities'], indent=2)}\\n\\n\"\n    \n        for case in test_cases:\n            prompt = few_shot_prompt + f\"Text: {case['text']}\\nEntities:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=150,\n                temperature=0.3\n            )\n    \n            # Extract JSON from response\n            try:\n                prediction = json.loads(response[\"choices\"][0][\"text\"].strip())\n                for entity_type, expected_value in case[\"expected\"].items():\n                    assert expected_value.lower() in prediction[entity_type].lower(), \\\n                        f\"Expected {expected_value} in {entity_type}\"\n            except json.JSONDecodeError:\n>               pytest.fail(\"Response is not valid JSON\")\nE               Failed: Response is not valid JSON\n\ntests/test_few_shot.py:216: Failed",
      "duration": 4.156525139000024,
      "timestamp": "2025-01-19T00:02:24.549359"
    },
    {
      "test_name": "tests/test_mathematics.py::test_arithmetic_operations",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec42ca40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7fbbec41e5e0>\n\n    @pytest.mark.asyncio\n    async def test_arithmetic_operations(llm_client, db_session, make_test_suite):\n        \"\"\"Test basic arithmetic operations.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"arithmetic\",\n            description=\"Tests for basic arithmetic operations\",\n            category=\"mathematics\"\n        )\n    \n        test_cases = [\n            {\n                \"prompt\": \"What is the result of multiplying 23.5 by 8.75?\",\n                \"expected\": 205.625\n            },\n            {\n                \"prompt\": \"What is 1234 divided by 56.5?\",\n                \"expected\": 21.84070796460177\n            }\n        ]\n    \n        for i, case in enumerate(test_cases):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Arithmetic Test {i+1}\",\n                test_type=\"arithmetic\",\n                input_data={\"prompt\": case[\"prompt\"]},\n                expected_output={\"result\": case[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for case in test_cases:\n            response = await client.generate(\n                prompt=f\"{case['prompt']} Provide only the numerical answer without any explanation.\",\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\n>           assert abs(result - case[\"expected\"]) < 0.01, \\\n                f\"Expected {case['expected']} but got {result}\"\nE           AssertionError: Expected 205.625 but got 204.375\nE           assert 1.25 < 0.01\nE            +  where 1.25 = abs((204.375 - 205.625))\n\ntests/test_mathematics.py:52: AssertionError",
      "duration": 0.29973949300000413,
      "timestamp": "2025-01-19T00:02:24.855775"
    },
    {
      "test_name": "tests/test_mathematics.py::test_word_problems",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec3a65c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7fbbec2b88b0>\n\n    @pytest.mark.asyncio\n    async def test_word_problems(llm_client, db_session, make_test_suite):\n        \"\"\"Test solving mathematical word problems.\"\"\"\n        client = await llm_client\n        suite = make_test_suite(\n            name_prefix=\"word_problems\",\n            description=\"Tests for mathematical word problems\",\n            category=\"mathematics\"\n        )\n    \n        problems = [\n            {\n                \"prompt\": \"\"\"\n                A store sells notebooks for $4.50 each. If a customer buys 12 notebooks\n                and has a 20% discount coupon, how much do they pay in total?\n                \"\"\",\n                \"expected\": 43.20\n            }\n        ]\n    \n        for i, problem in enumerate(problems):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Word Problem {i+1}\",\n                test_type=\"word_problem\",\n                input_data={\"prompt\": problem[\"prompt\"]},\n                expected_output={\"result\": problem[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for problem in problems:\n            response = await client.generate(\n                prompt=f\"{problem['prompt']} Provide only the numerical answer in dollars without any explanation.\",\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n>           result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\nE           ValueError: could not convert string to float: '$45.00'\n\ntests/test_mathematics.py:94: ValueError",
      "duration": 0.3054506100000083,
      "timestamp": "2025-01-19T00:02:25.176141"
    },
    {
      "test_name": "tests/test_mathematics.py::test_basic_algebra",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec2e0bc0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7fbbec2e25e0>\n\n    @pytest.mark.asyncio\n    async def test_basic_algebra(llm_client, db_session, make_test_suite):\n        \"\"\"Test basic algebraic equation solving.\"\"\"\n        client = await llm_client\n        suite = make_test_suite(\n            name_prefix=\"algebra\",\n            description=\"Tests for basic algebra\",\n            category=\"mathematics\"\n        )\n    \n        equations = [\n            {\n                \"prompt\": \"Solve for x: 3x + 7 = 22\",\n                \"expected\": 5\n            },\n            {\n                \"prompt\": \"Solve for x: 2x\u00b2 + 5x = 12\",\n                \"expected\": [1.5, -4]  # Both solutions\n            }\n        ]\n    \n        for i, eq in enumerate(equations):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Algebra Test {i+1}\",\n                test_type=\"algebra\",\n                input_data={\"prompt\": eq[\"prompt\"]},\n                expected_output={\"result\": eq[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        # Test first equation (single solution)\n        response = await client.generate(\n            prompt=f\"{equations[0]['prompt']} Provide only the numerical answer without any explanation.\",\n            max_tokens=50,\n            temperature=0.0\n        )\n    \n        result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\n>       assert abs(result - equations[0][\"expected\"]) < 0.01, \\\n            f\"Expected {equations[0]['expected']} but got {result}\"\nE       AssertionError: Expected 5 but got 15.0\nE       assert 10.0 < 0.01\nE        +  where 10.0 = abs((15.0 - 5))\n\ntests/test_mathematics.py:139: AssertionError",
      "duration": 0.21092080899998678,
      "timestamp": "2025-01-19T00:02:25.397906"
    },
    {
      "test_name": "tests/test_mathematics.py::test_mathematical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.20899842200000762,
      "timestamp": "2025-01-19T00:02:25.612551"
    },
    {
      "test_name": "tests/test_reasoning.py::test_logical_deduction",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec2e0c40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7fbbec46e3a0>\n\n    @pytest.mark.asyncio\n    async def test_logical_deduction(llm_client, db_session, make_test_suite):\n        \"\"\"Test logical deduction capabilities.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"logical_deduction\",\n            description=\"Tests for logical deduction\",\n            category=\"reasoning\"\n        )\n    \n        premises = \"\"\"\n        1. All programmers like coffee\n        2. Some coffee drinkers work at night\n        3. Alice is a programmer\n        \"\"\"\n    \n        questions = [\n            {\n                \"query\": \"Does Alice like coffee?\",\n                \"expected_keywords\": [\"yes\", \"true\", \"likes\", \"does\"]\n            },\n            {\n                \"query\": \"Do all programmers work at night?\",\n                \"expected_keywords\": [\"cannot\", \"unknown\", \"insufficient\", \"maybe\"]\n            }\n        ]\n    \n        for i, question in enumerate(questions):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Deduction Test {i+1}\",\n                test_type=\"logical_deduction\",\n                input_data={\n                    \"premises\": premises,\n                    \"question\": question[\"query\"]\n                },\n                expected_output={\"keywords\": question[\"expected_keywords\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for question in questions:\n            prompt = f\"\"\"\n            Given these premises:\n            {premises}\n    \n            Question: {question[\"query\"]}\n            Provide a direct answer without explanation.\n            \"\"\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            answer = response[\"choices\"][0][\"text\"].strip().lower()\n>           assert any(keyword in answer for keyword in question[\"expected_keywords\"]), \\\n                f\"Answer '{answer}' does not contain any expected keywords: {question['expected_keywords']}\"\nE           AssertionError: Answer 'no.' does not contain any expected keywords: ['cannot', 'unknown', 'insufficient', 'maybe']\nE           assert False\nE            +  where False = any(<generator object test_logical_deduction.<locals>.<genexpr> at 0x7fbbec43d7b0>)\n\ntests/test_reasoning.py:68: AssertionError",
      "duration": 0.519219382999978,
      "timestamp": "2025-01-19T00:02:26.141759"
    },
    {
      "test_name": "tests/test_reasoning.py::test_cause_effect_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 1.3055308259999947,
      "timestamp": "2025-01-19T00:02:27.453042"
    },
    {
      "test_name": "tests/test_reasoning.py::test_analogical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.21029733800000372,
      "timestamp": "2025-01-19T00:02:27.668737"
    },
    {
      "test_name": "tests/test_summarization.py::test_article_summarization",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7fbbec432dc0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7fbbec6d8280>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7fbbec46ee50>\n\n    @pytest.mark.asyncio\n    async def test_article_summarization(llm_client, db_session, make_test_suite):\n        \"\"\"Test article summarization capabilities.\"\"\"\n        # Need to await our async fixture\n        client = await llm_client\n    \n        # Create a uniquely named test suite\n        suite = make_test_suite(\n            name_prefix=\"summarization\",\n            description=\"Tests for text summarization capabilities\",\n            category=\"summarization\"\n        )\n    \n        # Test article\n        article = \"\"\"\n        The James Webb Space Telescope has revolutionized our view of the cosmos.\n        Launched in December 2021, this $10 billion observatory has provided\n        unprecedented views of distant galaxies, star-forming regions, and\n        exoplanets. Its infrared capabilities allow it to peer through cosmic\n        dust and see light from the earliest galaxies in the universe.\n        \"\"\"\n    \n        # Define expected key points\n        key_points = [\n            \"James Webb Space Telescope\",\n            \"launched December 2021\",\n            \"infrared observation\",\n            \"galaxies and exoplanets\"\n        ]\n    \n        # Create test case in database\n        test_case = UnitTest(\n            test_id=uuid.uuid4(),\n            suite_id=suite.suite_id,\n            test_name=\"Article Summarization\",\n            test_type=\"summarization\",\n            test_description=\"Test summarization of a scientific article\",\n            input_data={\"article\": article},\n            expected_output={\"key_points\": key_points}\n        )\n        db_session.add(test_case)\n        db_session.commit()\n    \n        # Get summary from model\n        response = await client.generate(\n            prompt=f\"Please summarize this article concisely: {article}\",\n            max_tokens=100,\n            temperature=0.3\n        )\n    \n        summary = response[\"choices\"][0][\"text\"].strip()\n    \n        # Check if key points are present\n        for point in key_points:\n>           assert point.lower() in summary.lower(), f\"Missing key point: {point}\"\nE           AssertionError: Missing key point: launched December 2021\nE           assert 'launched december 2021' in 'here is a concise summary of the article:\\n\\nthe james webb space telescope has transformed our understanding of the universe, offering unprecedented views of distant galaxies, star-forming regions, and exoplanets since its launch in december 2021.'\nE            +  where 'launched december 2021' = <built-in method lower of str object at 0x7fbbec74ada0>()\nE            +    where <built-in method lower of str object at 0x7fbbec74ada0> = 'launched December 2021'.lower\nE            +  and   'here is a concise summary of the article:\\n\\nthe james webb space telescope has transformed our understanding of the universe, offering unprecedented views of distant galaxies, star-forming regions, and exoplanets since its launch in december 2021.' = <built-in method lower of str object at 0x7fbbec908e90>()\nE            +    where <built-in method lower of str object at 0x7fbbec908e90> = 'Here is a concise summary of the article:\\n\\nThe James Webb Space Telescope has transformed our understanding of the universe, offering unprecedented views of distant galaxies, star-forming regions, and exoplanets since its launch in December 2021.'.lower\n\ntests/test_summarization.py:64: AssertionError",
      "duration": 1.9483974030000013,
      "timestamp": "2025-01-19T00:02:29.628447"
    },
    {
      "test_name": "tests/test_summarization.py::test_multi_document_summarization",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.0002687420000029306,
      "timestamp": "2025-01-19T00:02:29.634179"
    },
    {
      "test_name": "tests/test_summarization.py::test_bullet_point_extraction",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.0001926490000130343,
      "timestamp": "2025-01-19T00:02:29.635512"
    }
  ]
}