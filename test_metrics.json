{
  "metrics": {
    "coverage_rate": 100.0,
    "success_rate": 55.55555555555556,
    "partial_success_rate": 0.0
  },
  "status": "success",
  "model_name": "gpt-4o-mini",
  "timestamp": "2025-01-20T22:34:12.892321",
  "results": [
    {
      "test_name": "tests/test_code_generation.py::test_function_implementation",
      "outcome": "passed",
      "error_message": null,
      "duration": 6.552098677000004,
      "timestamp": "2025-01-20T22:33:48.525002"
    },
    {
      "test_name": "tests/test_code_generation.py::test_algorithm_solutions",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1eca9c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\n\n    @pytest.mark.asyncio\n    async def test_algorithm_solutions(llm_client, db_session):\n        \"\"\"Test implementation of common algorithms.\"\"\"\n        client = await llm_client\n    \n        algorithms = [\n            {\n                \"name\": \"Binary Search\",\n                \"prompt\": \"\"\"\n                Implement a binary search function in Python that finds the index of a\n                target value in a sorted list. Return -1 if the target is not found.\n                Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Input validation\",\n                    \"Handle empty list\",\n                    \"Return correct index\",\n                    \"Return -1 if not found\"\n                ]\n            },\n            {\n                \"name\": \"Merge Sort\",\n                \"prompt\": \"\"\"\n                Implement the merge sort algorithm in Python to sort a list of numbers\n                in ascending order. Return the code in a Python code block.\n                \"\"\",\n                \"requirements\": [\n                    \"Divide and conquer approach\",\n                    \"Merge function\",\n                    \"Handle empty or single-element lists\",\n                    \"Maintain stable sort\"\n                ]\n            }\n        ]\n    \n        for algo in algorithms:\n            response = await client.generate(\n                prompt=algo[\"prompt\"],\n                max_tokens=500,\n                temperature=0.0\n            )\n    \n            raw_code = response[\"choices\"][0][\"text\"].strip()\n            code = extract_code_block(raw_code)\n    \n            # Verify syntax\n            try:\n                ast.parse(code)\n            except SyntaxError as e:\n                pytest.fail(f\"Generated {algo['name']} code has syntax error: {e}\\nCode:\\n{code}\")\n    \n            # Check for algorithm-specific requirements\n            for req in algo[\"requirements\"]:\n>               assert any(keyword in code.lower() for keyword in req.lower().split()), \\\n                    f\"Missing requirement: {req}\"\nE               AssertionError: Missing requirement: Input validation\nE               assert False\nE                +  where False = any(<generator object test_algorithm_solutions.<locals>.<genexpr> at 0x7ff8d1ad5cf0>)\n\ntests/test_code_generation.py:138: AssertionError",
      "duration": 3.3117358300000035,
      "timestamp": "2025-01-20T22:33:51.881378"
    },
    {
      "test_name": "tests/test_code_generation.py::test_code_refactoring",
      "outcome": "passed",
      "error_message": null,
      "duration": 4.360590961,
      "timestamp": "2025-01-20T22:33:56.243736"
    },
    {
      "test_name": "tests/test_code_generation.py::test_error_handling",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1eca6c0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\n\n    @pytest.mark.asyncio\n    async def test_error_handling(llm_client, db_session):\n        \"\"\"Test generation of code with proper error handling.\"\"\"\n        client = await llm_client\n    \n        prompt = \"\"\"\n        Write a Python function that reads a JSON file and extracts specific fields.\n        The function should handle all possible errors (file not found, invalid JSON,\n        missing fields) gracefully. Return the code in a Python code block.\n        \"\"\"\n    \n        response = await client.generate(\n            prompt=prompt,\n            max_tokens=400,\n            temperature=0.0\n        )\n    \n        raw_code = response[\"choices\"][0][\"text\"].strip()\n        code = extract_code_block(raw_code)\n    \n        # Verify syntax first\n        try:\n            ast.parse(code)\n        except SyntaxError as e:\n            pytest.fail(f\"Generated code has syntax error: {e}\\nCode:\\n{code}\")\n    \n        # Check for error handling constructs\n        required_elements = [\n            \"try:\",\n            \"except\",\n            \"FileNotFoundError\",\n            \"json.JSONDecodeError\",\n            \"raise\"\n        ]\n    \n        for element in required_elements:\n>           assert element in code, f\"Missing error handling element: {element}\"\nE           AssertionError: Missing error handling element: FileNotFoundError\nE           assert 'FileNotFoundError' in 'import json\\nimport os\\n\\ndef extract_fields_from_json(file_path, fields):\\n    \"\"\"\\n    Extracts specific fields from a JSON file.\\n\\n    Parameters:\\n    - file_path: str, path to the JSON file\\n    - fields: list, list of fields to extract from the JSON\\n\\n    Returns:\\n    - dict: a dictionary containing the extracted fields and their values\\n    \"\"\"\\n    if not os.path.isfile(file_path):\\n        print(f\"Error: The file \\'{file_path}\\' was not found.\")\\n        return None\\n\\n    try:\\n        with open(file_path, \\'r\\') as file:\\n            data = json.load(file)\\n    except json.JSONDecodeError:\\n        print(f\"Error: The file \\'{file_path}\\' contains invalid JSON.\")\\n        return None\\n    except Exception as e:\\n        print(f\"An unexpected error occurred: {e}\")\\n        return None\\n\\n    extracted_data = {}\\n    for field in fields:\\n        if field in data:\\n            extracted_data[field] = data[field]\\n        else:\\n            print(f\"Warning: The field \\'{field}\\' is missing in the JSON data.\")\\n\\n    return extracted_data\\n\\n# Example usage:\\n# result = extract_fields_from_json(\\'data.json\\', [\\'name\\', \\'age\\', \\'email\\'])\\n# print(result)'\n\ntests/test_code_generation.py:238: AssertionError",
      "duration": 7.872379197000001,
      "timestamp": "2025-01-20T22:34:04.123171"
    },
    {
      "test_name": "tests/test_few_shot.py::test_sentiment_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.9985305490000087,
      "timestamp": "2025-01-20T22:34:05.123550"
    },
    {
      "test_name": "tests/test_few_shot.py::test_topic_classification",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1c47f40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\n\n    @pytest.mark.asyncio\n    async def test_topic_classification(llm_client, db_session):\n        \"\"\"Test topic classification with few-shot examples.\"\"\"\n        client = await llm_client\n    \n        examples = [\n            {\n                \"text\": \"Scientists discover new exoplanet in nearby solar system\",\n                \"topic\": \"science\"\n            },\n            {\n                \"text\": \"Local team wins championship in dramatic final\",\n                \"topic\": \"sports\"\n            },\n            {\n                \"text\": \"New smartphone features revolutionary camera technology\",\n                \"topic\": \"technology\"\n            }\n        ]\n    \n        test_articles = [\n            {\n                \"text\": \"Researchers develop breakthrough in quantum computing\",\n                \"expected\": \"technology\"\n            },\n            {\n                \"text\": \"Study reveals new insights into black hole formation\",\n                \"expected\": \"science\"\n            },\n            {\n                \"text\": \"Player breaks record for most goals in a season\",\n                \"expected\": \"sports\"\n            }\n        ]\n    \n        # Create few-shot prompt\n        few_shot_prompt = \"Classify the topic of the following text as science, sports, or technology:\\n\\n\"\n        for example in examples:\n            few_shot_prompt += f\"Text: {example['text']}\\nTopic: {example['topic']}\\n\\n\"\n    \n        for article in test_articles:\n            prompt = few_shot_prompt + f\"Text: {article['text']}\\nTopic:\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=50,\n                temperature=0.3\n            )\n    \n            prediction = response[\"choices\"][0][\"text\"].strip().lower()\n>           assert article[\"expected\"] in prediction, \\\n                f\"Expected {article['expected']} but got {prediction}\"\nE           AssertionError: Expected technology but got science\nE           assert 'technology' in 'science'\n\ntests/test_few_shot.py:103: AssertionError",
      "duration": 0.5712597389999985,
      "timestamp": "2025-01-20T22:34:05.701302"
    },
    {
      "test_name": "tests/test_few_shot.py::test_intent_classification",
      "outcome": "passed",
      "error_message": null,
      "duration": 1.1876825350000075,
      "timestamp": "2025-01-20T22:34:06.890635"
    },
    {
      "test_name": "tests/test_few_shot.py::test_entity_extraction",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.7334971869999976,
      "timestamp": "2025-01-20T22:34:07.625779"
    },
    {
      "test_name": "tests/test_mathematics.py::test_arithmetic_operations",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1c47440>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7ff8d1c69dc0>\n\n    @pytest.mark.asyncio\n    async def test_arithmetic_operations(llm_client, db_session, make_test_suite):\n        \"\"\"Test basic arithmetic operations.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"arithmetic\",\n            description=\"Tests for basic arithmetic operations\",\n            category=\"mathematics\"\n        )\n    \n        test_cases = [\n            {\n                \"prompt\": \"What is the result of multiplying 23.5 by 8.75?\",\n                \"expected\": 205.625\n            },\n            {\n                \"prompt\": \"What is 1234 divided by 56.5?\",\n                \"expected\": 21.84070796460177\n            }\n        ]\n    \n        for i, case in enumerate(test_cases):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Arithmetic Test {i+1}\",\n                test_type=\"arithmetic\",\n                input_data={\"prompt\": case[\"prompt\"]},\n                expected_output={\"result\": case[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for case in test_cases:\n            response = await client.generate(\n                prompt=f\"{case['prompt']} Provide only the numerical answer without any explanation.\",\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\n>           assert abs(result - case[\"expected\"]) < 0.01, \\\n                f\"Expected {case['expected']} but got {result}\"\nE           AssertionError: Expected 21.84070796460177 but got 21.88235294117647\nE           assert 0.041644976574701786 < 0.01\nE            +  where 0.041644976574701786 = abs((21.88235294117647 - 21.84070796460177))\n\ntests/test_mathematics.py:52: AssertionError",
      "duration": 0.7308054429999942,
      "timestamp": "2025-01-20T22:34:08.364616"
    },
    {
      "test_name": "tests/test_mathematics.py::test_word_problems",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1c47640>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7ff8d1b16b80>\n\n    @pytest.mark.asyncio\n    async def test_word_problems(llm_client, db_session, make_test_suite):\n        \"\"\"Test solving mathematical word problems.\"\"\"\n        client = await llm_client\n        suite = make_test_suite(\n            name_prefix=\"word_problems\",\n            description=\"Tests for mathematical word problems\",\n            category=\"mathematics\"\n        )\n    \n        problems = [\n            {\n                \"prompt\": \"\"\"\n                A store sells notebooks for $4.50 each. If a customer buys 12 notebooks\n                and has a 20% discount coupon, how much do they pay in total?\n                \"\"\",\n                \"expected\": 43.20\n            }\n        ]\n    \n        for i, problem in enumerate(problems):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Word Problem {i+1}\",\n                test_type=\"word_problem\",\n                input_data={\"prompt\": problem[\"prompt\"]},\n                expected_output={\"result\": problem[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for problem in problems:\n            response = await client.generate(\n                prompt=f\"{problem['prompt']} Provide only the numerical answer in dollars without any explanation.\",\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n>           result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\nE           ValueError: could not convert string to float: '$43.20'\n\ntests/test_mathematics.py:94: ValueError",
      "duration": 0.4463238120000028,
      "timestamp": "2025-01-20T22:34:08.828394"
    },
    {
      "test_name": "tests/test_mathematics.py::test_basic_algebra",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1bbbdc0>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7ff8d1bb9a60>\n\n    @pytest.mark.asyncio\n    async def test_basic_algebra(llm_client, db_session, make_test_suite):\n        \"\"\"Test basic algebraic equation solving.\"\"\"\n        client = await llm_client\n        suite = make_test_suite(\n            name_prefix=\"algebra\",\n            description=\"Tests for basic algebra\",\n            category=\"mathematics\"\n        )\n    \n        equations = [\n            {\n                \"prompt\": \"Solve for x: 3x + 7 = 22\",\n                \"expected\": 5\n            },\n            {\n                \"prompt\": \"Solve for x: 2x\u00b2 + 5x = 12\",\n                \"expected\": [1.5, -4]  # Both solutions\n            }\n        ]\n    \n        for i, eq in enumerate(equations):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Algebra Test {i+1}\",\n                test_type=\"algebra\",\n                input_data={\"prompt\": eq[\"prompt\"]},\n                expected_output={\"result\": eq[\"expected\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        # Test first equation (single solution)\n        response = await client.generate(\n            prompt=f\"{equations[0]['prompt']} Provide only the numerical answer without any explanation.\",\n            max_tokens=50,\n            temperature=0.0\n        )\n    \n>       result = float(response[\"choices\"][0][\"text\"].strip().split()[0])\nE       ValueError: could not convert string to float: 'x'\n\ntests/test_mathematics.py:138: ValueError",
      "duration": 0.5958538379999965,
      "timestamp": "2025-01-20T22:34:09.434770"
    },
    {
      "test_name": "tests/test_mathematics.py::test_mathematical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.3875751009999959,
      "timestamp": "2025-01-20T22:34:09.828243"
    },
    {
      "test_name": "tests/test_reasoning.py::test_logical_deduction",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1bbbd40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7ff8d1bf00d0>\n\n    @pytest.mark.asyncio\n    async def test_logical_deduction(llm_client, db_session, make_test_suite):\n        \"\"\"Test logical deduction capabilities.\"\"\"\n        client = await llm_client\n    \n        suite = make_test_suite(\n            name_prefix=\"logical_deduction\",\n            description=\"Tests for logical deduction\",\n            category=\"reasoning\"\n        )\n    \n        premises = \"\"\"\n        1. All programmers like coffee\n        2. Some coffee drinkers work at night\n        3. Alice is a programmer\n        \"\"\"\n    \n        questions = [\n            {\n                \"query\": \"Does Alice like coffee?\",\n                \"expected_keywords\": [\"yes\", \"true\", \"likes\", \"does\"]\n            },\n            {\n                \"query\": \"Do all programmers work at night?\",\n                \"expected_keywords\": [\"cannot\", \"unknown\", \"insufficient\", \"maybe\"]\n            }\n        ]\n    \n        for i, question in enumerate(questions):\n            test = UnitTest(\n                test_id=uuid.uuid4(),\n                suite_id=suite.suite_id,\n                test_name=f\"Deduction Test {i+1}\",\n                test_type=\"logical_deduction\",\n                input_data={\n                    \"premises\": premises,\n                    \"question\": question[\"query\"]\n                },\n                expected_output={\"keywords\": question[\"expected_keywords\"]}\n            )\n            db_session.add(test)\n        db_session.commit()\n    \n        for question in questions:\n            prompt = f\"\"\"\n            Given these premises:\n            {premises}\n    \n            Question: {question[\"query\"]}\n            Provide a direct answer without explanation.\n            \"\"\"\n    \n            response = await client.generate(\n                prompt=prompt,\n                max_tokens=50,\n                temperature=0.0\n            )\n    \n            answer = response[\"choices\"][0][\"text\"].strip().lower()\n>           assert any(keyword in answer for keyword in question[\"expected_keywords\"]), \\\n                f\"Answer '{answer}' does not contain any expected keywords: {question['expected_keywords']}\"\nE           AssertionError: Answer 'no, not all programmers work at night.' does not contain any expected keywords: ['cannot', 'unknown', 'insufficient', 'maybe']\nE           assert False\nE            +  where False = any(<generator object test_logical_deduction.<locals>.<genexpr> at 0x7ff8d1bf2740>)\n\ntests/test_reasoning.py:68: AssertionError",
      "duration": 0.8523484469999971,
      "timestamp": "2025-01-20T22:34:10.691028"
    },
    {
      "test_name": "tests/test_reasoning.py::test_cause_effect_analysis",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.4687382540000016,
      "timestamp": "2025-01-20T22:34:11.165574"
    },
    {
      "test_name": "tests/test_reasoning.py::test_analogical_reasoning",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.37359631200000365,
      "timestamp": "2025-01-20T22:34:11.544955"
    },
    {
      "test_name": "tests/test_summarization.py::test_article_summarization",
      "outcome": "failed",
      "error_message": "llm_client = <coroutine object llm_client at 0x7ff8d1c6cf40>\ndb_session = <sqlalchemy.orm.session.Session object at 0x7ff8d1f70d00>\nmake_test_suite = <function make_test_suite.<locals>._make_suite at 0x7ff8d1bf0b80>\n\n    @pytest.mark.asyncio\n    async def test_article_summarization(llm_client, db_session, make_test_suite):\n        \"\"\"Test article summarization capabilities.\"\"\"\n        # Need to await our async fixture\n        client = await llm_client\n    \n        # Create a uniquely named test suite\n        suite = make_test_suite(\n            name_prefix=\"summarization\",\n            description=\"Tests for text summarization capabilities\",\n            category=\"summarization\"\n        )\n    \n        # Test article\n        article = \"\"\"\n        The James Webb Space Telescope has revolutionized our view of the cosmos.\n        Launched in December 2021, this $10 billion observatory has provided\n        unprecedented views of distant galaxies, star-forming regions, and\n        exoplanets. Its infrared capabilities allow it to peer through cosmic\n        dust and see light from the earliest galaxies in the universe.\n        \"\"\"\n    \n        # Define expected key points\n        key_points = [\n            \"James Webb Space Telescope\",\n            \"launched December 2021\",\n            \"infrared observation\",\n            \"galaxies and exoplanets\"\n        ]\n    \n        # Create test case in database\n        test_case = UnitTest(\n            test_id=uuid.uuid4(),\n            suite_id=suite.suite_id,\n            test_name=\"Article Summarization\",\n            test_type=\"summarization\",\n            test_description=\"Test summarization of a scientific article\",\n            input_data={\"article\": article},\n            expected_output={\"key_points\": key_points}\n        )\n        db_session.add(test_case)\n        db_session.commit()\n    \n        # Get summary from model\n        response = await client.generate(\n            prompt=f\"Please summarize this article concisely: {article}\",\n            max_tokens=100,\n            temperature=0.3\n        )\n    \n        summary = response[\"choices\"][0][\"text\"].strip()\n    \n        # Check if key points are present\n        for point in key_points:\n>           assert point.lower() in summary.lower(), f\"Missing key point: {point}\"\nE           AssertionError: Missing key point: launched December 2021\nE           assert 'launched december 2021' in 'the james webb space telescope, launched in december 2021 at a cost of $10 billion, has transformed our understanding of the universe by offering unprecedented views of distant galaxies, star-forming regions, and exoplanets. its advanced infrared capabilities enable it to penetrate cosmic dust and observe light from the earliest galaxies.'\nE            +  where 'launched december 2021' = <built-in method lower of str object at 0x7ff8d1f9c030>()\nE            +    where <built-in method lower of str object at 0x7ff8d1f9c030> = 'launched December 2021'.lower\nE            +  and   'the james webb space telescope, launched in december 2021 at a cost of $10 billion, has transformed our understanding of the universe by offering unprecedented views of distant galaxies, star-forming regions, and exoplanets. its advanced infrared capabilities enable it to penetrate cosmic dust and observe light from the earliest galaxies.' = <built-in method lower of str object at 0x7ff8d1b15b20>()\nE            +    where <built-in method lower of str object at 0x7ff8d1b15b20> = 'The James Webb Space Telescope, launched in December 2021 at a cost of $10 billion, has transformed our understanding of the universe by offering unprecedented views of distant galaxies, star-forming regions, and exoplanets. Its advanced infrared capabilities enable it to penetrate cosmic dust and observe light from the earliest galaxies.'.lower\n\ntests/test_summarization.py:64: AssertionError",
      "duration": 1.3284674279999962,
      "timestamp": "2025-01-20T22:34:12.882860"
    },
    {
      "test_name": "tests/test_summarization.py::test_multi_document_summarization",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.00025355300000740044,
      "timestamp": "2025-01-20T22:34:12.889141"
    },
    {
      "test_name": "tests/test_summarization.py::test_bullet_point_extraction",
      "outcome": "passed",
      "error_message": null,
      "duration": 0.0002342859999941993,
      "timestamp": "2025-01-20T22:34:12.890677"
    }
  ]
}